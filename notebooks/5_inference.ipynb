{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuEZHU65y63kUxbweksqX0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_gU5-1_DzPg","executionInfo":{"status":"ok","timestamp":1754647170290,"user_tz":-330,"elapsed":20,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"88934fe8-0f5e-419a-99cd-628cdefcecfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Drive already mounted.\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model\n","from google.colab import drive\n","\n","from google.colab import drive\n","import os\n","\n","if not os.path.exists('/content/drive/MyDrive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"✅ Drive already mounted.\")\n","\n","# ===== Paths =====\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"  # change if needed\n","RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","OUTPUTS_DIR = os.path.join(BASE_DIR, \"outputs\")\n","\n","os.makedirs(OUTPUTS_DIR, exist_ok=True)\n","\n","# ===== File names =====\n","DATA_FILE = os.path.join(RAW_DIR, \"dataset.csv\")\n","SEGMENTS_FILE = os.path.join(RAW_DIR, \"segments.csv\")\n","SCALER_FILE = os.path.join(MODELS_DIR, \"scaler.pkl\")\n","AUTOENCODER_FILE = os.path.join(MODELS_DIR, \"autoencoder/lstm_autoencoder.h5\")\n","TTI_SCALER_FILE = os.path.join(MODELS_DIR, \"tti_scaler.pkl\")\n","TTI_MODEL_FILE = os.path.join(MODELS_DIR, \"tti_lstm_regressor.keras\")\n","\n","# Window length from training\n","TIME_STEPS = 30"]},{"cell_type":"code","source":["print(\"📂 Loading telemetry dataset...\")\n","df = pd.read_csv(DATA_FILE)\n","print(f\"✅ Raw shape: {df.shape}\")\n","\n","df_features = df.drop(columns=['anomaly', 'channel'], errors='ignore')\n","\n","# ===== Load scaler from training =====\n","scaler = joblib.load(SCALER_FILE)\n","df_scaled = pd.DataFrame(scaler.transform(df_features), columns=df_features.columns)\n","print(\"✅ Data scaled.\")\n","\n","# ===== Create sliding windows =====\n","def create_sequences(data, time_steps=TIME_STEPS):\n","    sequences = []\n","    for i in range(len(data) - time_steps + 1):\n","        sequences.append(data[i:i+time_steps])\n","    return np.array(sequences)\n","\n","X_seq = create_sequences(df_scaled.values)\n","print(f\"✅ Created sequences: {X_seq.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1LI2ixDE5VN","executionInfo":{"status":"ok","timestamp":1754647127444,"user_tz":-330,"elapsed":35,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"f9614b39-1f15-4bcc-bde6-5ce3e57b59a2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["📂 Loading telemetry dataset...\n","✅ Raw shape: (2123, 23)\n","✅ Data scaled.\n","✅ Created sequences: (2094, 30, 21)\n"]}]},{"cell_type":"code","source":["print(\"📂 Loading models...\")\n","autoencoder = load_model(AUTOENCODER_FILE)\n","tti_model = load_model(TTI_MODEL_FILE)\n","tti_scaler = joblib.load(TTI_SCALER_FILE)\n","print(\"✅ All models loaded successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rE3IVVRiHqLV","executionInfo":{"status":"ok","timestamp":1754647177826,"user_tz":-330,"elapsed":3740,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"d9acea8e-9e8b-42d1-9397-2b62551c02b1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["📂 Loading models...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["✅ All models loaded successfully.\n"]}]},{"cell_type":"code","source":["# ===== Reconstruction errors =====\n","X_pred = autoencoder.predict(X_seq)\n","mse = np.mean(np.square(X_seq - X_pred), axis=(1, 2))\n","\n","# Threshold — same as training\n","THRESHOLD = np.percentile(mse, 95)  # example: 95th percentile\n","anomalies_idx = np.where(mse > THRESHOLD)[0]\n","\n","print(f\"🚨 Detected {len(anomalies_idx)} anomalies.\")\n","\n","# Extract anomaly sequences\n","X_anomalies = X_seq[anomalies_idx]\n","print(f\"✅ X_anomalies shape: {X_anomalies.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzP2oNaoHzQw","executionInfo":{"status":"ok","timestamp":1754647200386,"user_tz":-330,"elapsed":2724,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"e1870794-4f22-40fd-ef3c-ad3039a01de2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n","🚨 Detected 105 anomalies.\n","✅ X_anomalies shape: (105, 30, 21)\n"]}]},{"cell_type":"code","source":["# ===== Cell 5: Scaling for TTI model =====\n","\n","print(\"📏 Scaling anomaly sequences for TTI model...\")\n","\n","# X_anomalies shape should be (num_samples, TIME_STEPS, num_features)\n","num_samples, time_steps, num_features = X_anomalies.shape\n","\n","# ✅ Reshape to 2D (combine samples & timesteps) for scaling\n","X_anomalies_2d = X_anomalies.reshape(-1, num_features)  # shape: (num_samples * time_steps, num_features)\n","\n","# ===== Load scaler from training =====\n","tti_scaler = joblib.load(TTI_SCALER_FILE)\n","\n","# ✅ Scale using the training scaler\n","X_anomalies_scaled_2d = tti_scaler.transform(X_anomalies_2d)\n","\n","# ✅ Reshape back to original 3D shape\n","X_anomalies_scaled = X_anomalies_scaled_2d.reshape(num_samples, time_steps, num_features)\n","\n","print(f\"✅ Data scaled for TTI model: {X_anomalies_scaled.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvxtMyWuH5vV","executionInfo":{"status":"ok","timestamp":1754647521139,"user_tz":-330,"elapsed":18,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"70fa96de-d7cd-48cf-8d48-eb343806f983"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["📏 Scaling anomaly sequences for TTI model...\n","✅ Data scaled for TTI model: (105, 30, 21)\n"]}]},{"cell_type":"code","source":["# ===== Cell 6: Predict TTI for detected anomalies (shape-safe) =====\n","\n","if len(X_anomalies) == 0:\n","    print(\"⚠ No anomalies detected — skipping TTI prediction.\")\n","    y_pred_tti = np.array([])\n","else:\n","    # Flatten only the feature dimension for scaling\n","    n_samples, n_steps, n_features = X_anomalies.shape  # e.g., (samples, TIME_STEPS, 21)\n","    X_anomalies_reshaped = X_anomalies.reshape(-1, n_features)  # (samples * TIME_STEPS, 21)\n","\n","    # Scale each timestep’s features\n","    X_anomalies_scaled = tti_scaler.transform(X_anomalies_reshaped)\n","\n","    # Reshape back to LSTM format\n","    X_anomalies_scaled = X_anomalies_scaled.reshape(n_samples, n_steps, n_features)\n","\n","    # Predict TTI\n","    y_pred_tti = tti_model.predict(X_anomalies_scaled)\n","\n","    print(f\"✅ TTI predictions completed. Shape: {y_pred_tti.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7ciwA-GJjao","executionInfo":{"status":"ok","timestamp":1754648434806,"user_tz":-330,"elapsed":132,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"9d3a2953-ffeb-45f9-f81d-157f53423f06"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n","✅ TTI predictions completed. Shape: (105, 1)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","from tensorflow import keras\n","\n","# Paths\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"\n","PROCESSED_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","\n","# Load scaled data - assuming shape (num_samples, num_features)\n","X_full_flat = np.load(os.path.join(PROCESSED_DIR, \"X_full.npy\"))\n","print(f\"✅ Loaded X_full (flat): {X_full_flat.shape}\")\n","\n","# Parameters\n","TIME_STEPS = 30  # must match your model's expected input time steps\n","FEATURES = X_full_flat.shape[1]\n","\n","# Convert flat data into overlapping sequences for LSTM input\n","def create_sequences(data, window_size=TIME_STEPS):\n","    sequences = []\n","    for i in range(len(data) - window_size + 1):\n","        sequences.append(data[i:i+window_size])\n","    return np.array(sequences)\n","\n","X_full_seq = create_sequences(X_full_flat)\n","print(f\"✅ Created sequences: {X_full_seq.shape} (samples, timesteps, features)\")\n","\n","# Load autoencoder\n","autoencoder = keras.models.load_model(os.path.join(MODELS_DIR, \"autoencoder/lstm_autoencoder.h5\"))\n","print(\"✅ Autoencoder model loaded.\")\n","\n","# Predict reconstruction\n","X_pred = autoencoder.predict(X_full_seq)\n","print(f\"✅ Reconstruction predictions done: {X_pred.shape}\")\n","\n","# Compute reconstruction error per sequence (mean squared error)\n","reconstruction_errors = np.mean(np.square(X_full_seq - X_pred), axis=(1,2))\n","print(f\"✅ Computed reconstruction errors: {reconstruction_errors.shape}\")\n","\n","# Save reconstruction errors\n","errors_path = os.path.join(PROCESSED_DIR, \"reconstruction_errors.npy\")\n","np.save(errors_path, reconstruction_errors)\n","print(f\"✅ Saved reconstruction errors at {errors_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYU69T3wPYav","executionInfo":{"status":"ok","timestamp":1754649291126,"user_tz":-330,"elapsed":1892,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"76fbadfe-2d63-471d-a039-58f2290f194d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Loaded X_full (flat): (2123, 21)\n","✅ Created sequences: (2094, 30, 21) (samples, timesteps, features)\n","✅ Autoencoder model loaded.\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n","✅ Reconstruction predictions done: (2094, 30, 21)\n","✅ Computed reconstruction errors: (2094,)\n","✅ Saved reconstruction errors at /content/drive/MyDrive/spacecraft_anomaly_project/data/processed/reconstruction_errors.npy\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","\n","# ===== Paths =====\n","PROCESSED_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project/data/processed\"\n","\n","# ===== Load reconstruction errors (make sure you have this file saved earlier) =====\n","reconstruction_errors_path = os.path.join(PROCESSED_DIR, \"reconstruction_errors.npy\")\n","reconstruction_errors = np.load(reconstruction_errors_path)\n","print(f\"✅ Loaded reconstruction errors: {reconstruction_errors.shape}\")\n","\n","# ===== Define threshold to detect anomalies =====\n","threshold = 0.1  # Adjust this based on your dataset and error distribution\n","\n","# ===== Detect anomalies where error exceeds threshold =====\n","anomaly_indices = np.where(reconstruction_errors > threshold)[0]\n","print(f\"✅ Detected {len(anomaly_indices)} anomaly indices\")\n","\n","# ===== Save anomaly indices for future use =====\n","anomaly_indices_path = os.path.join(PROCESSED_DIR, \"anomaly_indices.npy\")\n","np.save(anomaly_indices_path, anomaly_indices)\n","print(f\"✅ Saved anomaly indices to: {anomaly_indices_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3M45N0-hPN7S","executionInfo":{"status":"ok","timestamp":1754649294152,"user_tz":-330,"elapsed":39,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"ccebd4de-4b1e-44b4-b7c2-135a6b085e0d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded reconstruction errors: (2094,)\n","✅ Detected 2094 anomaly indices\n","✅ Saved anomaly indices to: /content/drive/MyDrive/spacecraft_anomaly_project/data/processed/anomaly_indices.npy\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","# === Paths ===\n","RAW_DIR = '/content/drive/MyDrive/spacecraft_anomaly_project/data/raw'\n","PROCESSED_DIR = '/content/drive/MyDrive/spacecraft_anomaly_project/data/processed'\n","\n","# === Load anomaly indices ===\n","anomaly_indices_path = os.path.join(PROCESSED_DIR, 'anomaly_indices.npy')\n","anomaly_indices = np.load(anomaly_indices_path)\n","print(f\"✅ Loaded anomaly indices: {anomaly_indices.shape[0]} anomalies\")\n","\n","# === Load raw dataset ===\n","df_raw = pd.read_csv(os.path.join(RAW_DIR, 'dataset.csv'))\n","print(f\"✅ Loaded raw dataset: {df_raw.shape[0]} rows, {df_raw.shape[1]} columns\")\n","\n","# === Create synthetic timestamps with lowercase 's' ===\n","sampling_interval_seconds = 1  # Adjust if needed\n","df_raw['timestamp'] = pd.date_range(start='2020-01-01 00:00:00', periods=len(df_raw), freq=f'{sampling_interval_seconds}s')\n","timestamps = df_raw['timestamp'].values\n","print(f\"✅ Created synthetic timestamps: {len(timestamps)} entries\")\n","\n","# === Define window size used in anomaly detection ===\n","window_size = 30  # adjust if you used a different window size\n","\n","# === Build anomalies DataFrame ===\n","anomaly_windows = []\n","for idx in anomaly_indices:\n","    end_idx = min(idx + window_size - 1, len(timestamps) - 1)\n","    start_time = timestamps[idx]\n","    end_time = timestamps[end_idx]\n","\n","    # Convert numpy.timedelta64 to seconds correctly\n","    duration = (end_time - start_time) / np.timedelta64(1, 's')  # duration in seconds\n","\n","    anomaly_windows.append({'start_time': start_time, 'end_time': end_time, 'duration_sec': duration})\n","\n","anomalies_df = pd.DataFrame(anomaly_windows)\n","print(\"✅ Created anomalies DataFrame:\")\n","print(anomalies_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHJWq5ddObfH","executionInfo":{"status":"ok","timestamp":1754649819183,"user_tz":-330,"elapsed":50,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"620ce27a-82c5-470c-e163-81a29ab4dae4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded anomaly indices: 2094 anomalies\n","✅ Loaded raw dataset: 2123 rows, 23 columns\n","✅ Created synthetic timestamps: 2123 entries\n","✅ Created anomalies DataFrame:\n","           start_time            end_time  duration_sec\n","0 2020-01-01 00:00:00 2020-01-01 00:00:29          29.0\n","1 2020-01-01 00:00:01 2020-01-01 00:00:30          29.0\n","2 2020-01-01 00:00:02 2020-01-01 00:00:31          29.0\n","3 2020-01-01 00:00:03 2020-01-01 00:00:32          29.0\n","4 2020-01-01 00:00:04 2020-01-01 00:00:33          29.0\n"]}]},{"cell_type":"code","source":["# ===== Cell 7: Predict TTI and prioritize anomalies for ground station =====\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Paths\n","PROCESSED_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project/data/processed\"\n","RAW_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project/data/raw\"\n","OUTPUTS_DIR = os.path.join(PROCESSED_DIR, \"outputs\")\n","os.makedirs(OUTPUTS_DIR, exist_ok=True)\n","\n","# Load the subset of anomaly indices that correspond to X_anomalies_scaled\n","tti_anomaly_indices_path = os.path.join(PROCESSED_DIR, \"anomaly_indices.npy\")\n","tti_anomaly_indices = np.load(tti_anomaly_indices_path)\n","print(f\"✅ Loaded {len(tti_anomaly_indices)} anomaly indices for TTI prediction\")\n","\n","# Load raw dataset to get timestamps\n","df_raw = pd.read_csv(os.path.join(RAW_DIR, \"dataset.csv\"))\n","\n","# Create synthetic timestamps if needed (adjust if real timestamps exist)\n","if \"timestamp\" not in df_raw.columns:\n","    sampling_interval_seconds = 1  # or the actual sampling interval you used\n","    df_raw[\"timestamp\"] = pd.date_range(start=\"2020-01-01 00:00:00\", periods=len(df_raw), freq=f\"{sampling_interval_seconds}s\")\n","\n","timestamps = pd.to_datetime(df_raw[\"timestamp\"]).values\n","\n","# Define window size (used during anomaly window creation)\n","window_size = 30\n","\n","# Build anomalies DataFrame only for tti_anomaly_indices\n","anomaly_windows = []\n","for idx in tti_anomaly_indices:\n","    end_idx = min(idx + window_size - 1, len(timestamps) - 1)\n","    start_time = timestamps[idx]\n","    end_time = timestamps[end_idx]\n","    duration_sec = (end_time - start_time) / np.timedelta64(1, 's')\n","    anomaly_windows.append({\"start_time\": start_time, \"end_time\": end_time, \"duration_sec\": duration_sec})\n","\n","anomalies_df = pd.DataFrame(anomaly_windows)\n","print(f\"✅ Created anomalies DataFrame with {len(anomalies_df)} entries\")\n","\n","# Predict TTI using the loaded LSTM regressor\n","print(f\"✅ Input shape to TTI model: {X_anomalies_scaled.shape}\")\n","y_pred_tti = tti_model.predict(X_anomalies_scaled)\n","print(\"✅ TTI predictions complete.\")\n","\n","# Add predicted TTI to anomalies DataFrame (lengths match!)\n","anomalies_df[\"predicted_TTI\"] = y_pred_tti.flatten()\n","\n","# Sort anomalies by shortest predicted TTI\n","anomalies_sorted = anomalies_df.sort_values(by=\"predicted_TTI\", ascending=True)\n","\n","# Optional: filter anomalies below TTI threshold\n","TTI_THRESHOLD = 100  # seconds (adjust as needed)\n","filtered_anomalies = anomalies_sorted[anomalies_sorted[\"predicted_TTI\"] < TTI_THRESHOLD]\n","\n","# Limit to top N anomalies\n","TOP_N = 20  # adjust as needed\n","high_priority_anomalies = filtered_anomalies.head(TOP_N)\n","\n","# Show selected anomalies\n","print(f\"✅ High-priority anomalies for transmission (Top {TOP_N} with TTI < {TTI_THRESHOLD}s):\")\n","display(high_priority_anomalies)\n","\n","# Save prioritized anomalies to outputs folder\n","output_file = os.path.join(OUTPUTS_DIR, \"prioritized_anomalies.csv\")\n","high_priority_anomalies.to_csv(output_file, index=False)\n","print(f\"📁 Saved prioritized anomalies to {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"HEVfDrVhJmDH","executionInfo":{"status":"error","timestamp":1754651288839,"user_tz":-330,"elapsed":303,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"e4b2c8d6-1c9c-4ade-a87b-9d08406dcf89"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded 2094 anomaly indices for TTI prediction\n","✅ Created anomalies DataFrame with 2094 entries\n","✅ Input shape to TTI model: (105, 30, 21)\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n","✅ TTI predictions complete.\n"]},{"output_type":"error","ename":"ValueError","evalue":"Length of values (105) does not match length of index (2094)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2112100446.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Add predicted TTI to anomalies DataFrame (lengths match!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0manomalies_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_TTI\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_tti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Sort anomalies by shortest predicted TTI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5266\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5267\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5268\u001b[0m         if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length of values (105) does not match length of index (2094)"]}]},{"cell_type":"code","source":["print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4lUdwC7QSC_","executionInfo":{"status":"ok","timestamp":1754649407749,"user_tz":-330,"elapsed":54,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"133bf4f3-7df2-49f6-9e59-1f094692c628"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['segment', 'anomaly', 'train', 'channel', 'sampling', 'duration', 'len',\n","       'mean', 'var', 'std', 'kurtosis', 'skew', 'n_peaks', 'smooth10_n_peaks',\n","       'smooth20_n_peaks', 'diff_peaks', 'diff2_peaks', 'diff_var',\n","       'diff2_var', 'gaps_squared', 'len_weighted', 'var_div_duration',\n","       'var_div_len'],\n","      dtype='object')\n"]}]}]}