{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1C-bVWv8RJG5RO5h4A2WNcUnq9H5hI7MW","authorship_tag":"ABX9TyObb50zbRBW0Q0CJQJdAVhr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Create X_anomalies\n","import os\n","import numpy as np\n","import joblib\n","import tensorflow as tf\n","\n","# === Paths ===\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"\n","PROCESSED_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n","MODEL_DIR = os.path.join(BASE_DIR, \"models/autoencoder\")\n","\n","# === Load Scaler ===\n","scaler_path = os.path.join(PROCESSED_DIR, \"scaler.pkl\")\n","scaler = joblib.load(scaler_path)\n","print(\"âœ… Scaler loaded.\")\n","\n","# === Load X_full (scaled data) ===\n","x_full_path = os.path.join(PROCESSED_DIR, \"X_full.npy\")\n","X_full = np.load(x_full_path)\n","print(f\"âœ… X_full loaded: shape = {X_full.shape}\")\n","\n","# === Reshape if needed for LSTM ===\n","# Assuming the shape for training was (samples, timesteps, features)\n","# Change 'timesteps' to match what you used during training\n","TIMESTEPS = 30\n","n_features = X_full.shape[1]\n","\n","X_full_seq = []\n","for i in range(len(X_full) - TIMESTEPS + 1):\n","    X_full_seq.append(X_full[i:i+TIMESTEPS])\n","X_full_seq = np.array(X_full_seq)\n","print(f\"âœ… Reshaped for LSTM: {X_full_seq.shape}\")\n","\n","# === Load trained autoencoder ===\n","autoencoder_path = os.path.join(MODEL_DIR, \"lstm_autoencoder.h5\")\n","autoencoder = tf.keras.models.load_model(autoencoder_path)\n","print(\"âœ… Autoencoder loaded.\")\n","\n","# === Compute reconstruction error ===\n","X_full_pred = autoencoder.predict(X_full_seq)\n","recon_errors = np.mean(np.square(X_full_seq - X_full_pred), axis=(1, 2))\n","\n","# === Set anomaly threshold ===\n","# Option 1: Fixed threshold\n","threshold = np.percentile(recon_errors, 95)  # top 5% errors = anomalies\n","# Option 2: Use previously saved threshold if available\n","# threshold = joblib.load(os.path.join(PROCESSED_DIR, \"threshold.pkl\"))\n","\n","print(f\"ğŸ“ Using threshold: {threshold}\")\n","\n","# === Detect anomalies ===\n","anomaly_flags = recon_errors > threshold\n","print(f\"ğŸš¨ Detected {np.sum(anomaly_flags)} anomalies out of {len(anomaly_flags)} sequences.\")\n","\n","# === Extract anomaly windows ===\n","X_anomalies = X_full_seq[anomaly_flags]\n","print(f\"âœ… X_anomalies shape: {X_anomalies.shape}\")\n","\n","# === Save anomalies for TTI model ===\n","np.save(os.path.join(PROCESSED_DIR, \"X_anomalies.npy\"), X_anomalies)\n","print(\"ğŸ’¾ X_anomalies.npy saved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeefSNwGq9Ru","executionInfo":{"status":"ok","timestamp":1754640661850,"user_tz":-330,"elapsed":5838,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"e1919fe5-f5c0-4190-992d-dceccc3d587f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Scaler loaded.\n","âœ… X_full loaded: shape = (2123, 21)\n","âœ… Reshaped for LSTM: (2094, 30, 21)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["âœ… Autoencoder loaded.\n","\u001b[1m66/66\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step\n","ğŸ“ Using threshold: 3.097266131730625\n","ğŸš¨ Detected 105 anomalies out of 2094 sequences.\n","âœ… X_anomalies shape: (105, 30, 21)\n","ğŸ’¾ X_anomalies.npy saved.\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import joblib\n","from sklearn.preprocessing import StandardScaler\n","\n","# Paths\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"\n","PROCESSED_DIR = os.path.join(BASE_DIR, \"data/processed\")\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","os.makedirs(MODELS_DIR, exist_ok=True)\n","\n","# Load the full scaled data\n","X_full = np.load(os.path.join(PROCESSED_DIR, 'X_full.npy'))\n","print(f\"âœ… X_full loaded: shape = {X_full.shape}\")\n","\n","# Fit scaler for TTI model (no flattening needed)\n","tti_scaler = StandardScaler()\n","tti_scaler.fit(X_full)\n","\n","# Save the TTI scaler\n","joblib.dump(tti_scaler, os.path.join(MODELS_DIR, 'tti_scaler.pkl'))\n","print(\"âœ… TTI scaler saved at:\", os.path.join(MODELS_DIR, 'tti_scaler.pkl'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyB4PmPg1Gxx","executionInfo":{"status":"ok","timestamp":1754642366555,"user_tz":-330,"elapsed":62,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"ed30ba17-58aa-4d1a-de1e-71ca67380619"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… X_full loaded: shape = (2123, 21)\n","âœ… TTI scaler saved at: /content/drive/MyDrive/spacecraft_anomaly_project/models/tti_scaler.pkl\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pickle\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# ==============================\n","# CONFIG\n","# ==============================\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","DATA_DIR = os.path.join(BASE_DIR, \"data/processed\")\n","\n","os.makedirs(MODELS_DIR, exist_ok=True)\n","\n","# ==============================\n","# LOAD ANOMALIES\n","# ==============================\n","X_anomalies = np.load(os.path.join(DATA_DIR, \"X_anomalies.npy\"))\n","print(f\"âœ… Loaded anomalies: {X_anomalies.shape}\")  # (samples, timesteps, features)\n","\n","# Optional: Load reconstruction errors\n","reconstruction_errors_path = os.path.join(DATA_DIR, \"reconstruction_errors.npy\")\n","if os.path.exists(reconstruction_errors_path):\n","    reconstruction_errors = np.load(reconstruction_errors_path)\n","    print(\"âœ… Loaded reconstruction errors for severity-weighted TTI generation.\")\n","else:\n","    reconstruction_errors = None\n","    print(\"âš ï¸ No reconstruction errors found, using random TTI generation.\")\n","\n","# ==============================\n","# GENERATE SYNTHETIC TTI LABELS\n","# ==============================\n","min_tti = 300      # 5 minutes\n","max_tti = 7200     # 2 hours\n","\n","if reconstruction_errors is not None:\n","    errors = (reconstruction_errors - reconstruction_errors.min()) / (reconstruction_errors.max() - reconstruction_errors.min() + 1e-8)\n","    y_tti_synthetic = max_tti - (errors * (max_tti - min_tti)).astype(int)\n","else:\n","    y_tti_synthetic = np.random.randint(min_tti, max_tti + 1, size=X_anomalies.shape[0])\n","\n","print(f\"âœ… Synthetic TTI labels generated. Example: {y_tti_synthetic[:10]}\")\n","\n","# ==============================\n","# SCALE FEATURES\n","# ==============================\n","# Scale per-feature across all timesteps\n","n_samples, timesteps, n_features = X_anomalies.shape\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_anomalies.reshape(-1, n_features)).reshape(n_samples, timesteps, n_features)\n","\n","# ==============================\n","# BUILD LSTM REGRESSOR\n","# ==============================\n","model = Sequential([\n","    LSTM(64, activation='tanh', input_shape=(timesteps, n_features), return_sequences=False),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dense(1)  # Output TTI in seconds\n","])\n","\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# ==============================\n","# TRAIN MODEL\n","# ==============================\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","checkpoint = ModelCheckpoint(\n","    os.path.join(MODELS_DIR, \"tti_lstm_regressor.keras\"),\n","    save_best_only=True,\n","    monitor='val_loss'\n",")\n","\n","history = model.fit(\n","    X_scaled, y_tti_synthetic,\n","    validation_split=0.2,\n","    epochs=50,\n","    batch_size=32,\n","    callbacks=[early_stop, checkpoint],\n","    verbose=1\n",")\n","\n","print(\"âœ… LSTM regressor trained and saved.\")\n","\n","# ==============================\n","# SAVE SCALER\n","# ==============================\n","with open(os.path.join(MODELS_DIR, \"tti_scaler.pkl\"), \"wb\") as f:\n","    pickle.dump(scaler, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFPdOpDd6X-W","executionInfo":{"status":"ok","timestamp":1754643884868,"user_tz":-330,"elapsed":16094,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"f4fc93cb-cb98-4a27-b803-fd6c4be9bb6b"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Loaded anomalies: (105, 30, 21)\n","âš ï¸ No reconstruction errors found, using random TTI generation.\n","âœ… Synthetic TTI labels generated. Example: [2311 1114 4113 6574 6391 3296  821 6903 2222  786]\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334ms/step - loss: 19162016.0000 - mae: 3806.3975 - val_loss: 16713469.0000 - val_mae: 3593.8535\n","Epoch 2/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 17813620.0000 - mae: 3630.1555 - val_loss: 16711421.0000 - val_mae: 3593.5696\n","Epoch 3/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 17049676.0000 - mae: 3512.1584 - val_loss: 16709051.0000 - val_mae: 3593.2410\n","Epoch 4/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 17856628.0000 - mae: 3604.9946 - val_loss: 16705926.0000 - val_mae: 3592.8059\n","Epoch 5/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 18344324.0000 - mae: 3756.4771 - val_loss: 16701882.0000 - val_mae: 3592.2415\n","Epoch 6/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 19523624.0000 - mae: 3839.4429 - val_loss: 16696431.0000 - val_mae: 3591.4829\n","Epoch 7/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 18682262.0000 - mae: 3708.3740 - val_loss: 16690165.0000 - val_mae: 3590.6116\n","Epoch 8/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18997400.0000 - mae: 3783.3020 - val_loss: 16683464.0000 - val_mae: 3589.6785\n","Epoch 9/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 17908574.0000 - mae: 3637.8250 - val_loss: 16676698.0000 - val_mae: 3588.7358\n","Epoch 10/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 19455782.0000 - mae: 3812.5610 - val_loss: 16669861.0000 - val_mae: 3587.7834\n","Epoch 11/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 18687812.0000 - mae: 3725.7036 - val_loss: 16662883.0000 - val_mae: 3586.8105\n","Epoch 12/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 19458204.0000 - mae: 3816.3311 - val_loss: 16655468.0000 - val_mae: 3585.7778\n","Epoch 13/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 19333064.0000 - mae: 3779.7688 - val_loss: 16647698.0000 - val_mae: 3584.6948\n","Epoch 14/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 18607504.0000 - mae: 3728.5854 - val_loss: 16639168.0000 - val_mae: 3583.5051\n","Epoch 15/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 19580868.0000 - mae: 3849.7532 - val_loss: 16629940.0000 - val_mae: 3582.2173\n","Epoch 16/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 18520278.0000 - mae: 3686.2781 - val_loss: 16620261.0000 - val_mae: 3580.8667\n","Epoch 17/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 17101170.0000 - mae: 3503.8442 - val_loss: 16610187.0000 - val_mae: 3579.4604\n","Epoch 18/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 19060536.0000 - mae: 3818.2070 - val_loss: 16599197.0000 - val_mae: 3577.9241\n","Epoch 19/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 18638904.0000 - mae: 3731.8953 - val_loss: 16586850.0000 - val_mae: 3576.1982\n","Epoch 20/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 19421526.0000 - mae: 3857.5898 - val_loss: 16571383.0000 - val_mae: 3574.0334\n","Epoch 21/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 19301432.0000 - mae: 3786.9578 - val_loss: 16553778.0000 - val_mae: 3571.5688\n","Epoch 22/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 20661202.0000 - mae: 3985.7627 - val_loss: 16535040.0000 - val_mae: 3568.9419\n","Epoch 23/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18077136.0000 - mae: 3634.2446 - val_loss: 16515465.0000 - val_mae: 3566.1975\n","Epoch 24/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 18866900.0000 - mae: 3753.8374 - val_loss: 16495147.0000 - val_mae: 3563.3486\n","Epoch 25/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 17945914.0000 - mae: 3643.7314 - val_loss: 16474685.0000 - val_mae: 3560.4771\n","Epoch 26/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 19349766.0000 - mae: 3851.5437 - val_loss: 16452599.0000 - val_mae: 3557.3755\n","Epoch 27/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 18750460.0000 - mae: 3743.6770 - val_loss: 16432027.0000 - val_mae: 3554.4832\n","Epoch 28/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18785502.0000 - mae: 3756.8247 - val_loss: 16412123.0000 - val_mae: 3551.6824\n","Epoch 29/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 19105708.0000 - mae: 3767.0225 - val_loss: 16391266.0000 - val_mae: 3548.7441\n","Epoch 30/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18437294.0000 - mae: 3698.6670 - val_loss: 16370264.0000 - val_mae: 3545.7842\n","Epoch 31/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18043474.0000 - mae: 3643.4121 - val_loss: 16349154.0000 - val_mae: 3542.8059\n","Epoch 32/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 16772568.0000 - mae: 3462.3186 - val_loss: 16327797.0000 - val_mae: 3539.7905\n","Epoch 33/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 18145136.0000 - mae: 3696.4268 - val_loss: 16306082.0000 - val_mae: 3536.7214\n","Epoch 34/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18920788.0000 - mae: 3766.8689 - val_loss: 16284123.0000 - val_mae: 3533.6152\n","Epoch 35/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18018294.0000 - mae: 3642.5063 - val_loss: 16261993.0000 - val_mae: 3530.4829\n","Epoch 36/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 18058614.0000 - mae: 3668.0850 - val_loss: 16239552.0000 - val_mae: 3527.3027\n","Epoch 37/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18581452.0000 - mae: 3743.3462 - val_loss: 16216812.0000 - val_mae: 3524.0781\n","Epoch 38/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 18290874.0000 - mae: 3669.1348 - val_loss: 16193838.0000 - val_mae: 3520.8169\n","Epoch 39/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 17561972.0000 - mae: 3596.5469 - val_loss: 16170709.0000 - val_mae: 3517.5312\n","Epoch 40/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 18083212.0000 - mae: 3653.1733 - val_loss: 16147270.0000 - val_mae: 3514.1975\n","Epoch 41/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 17796552.0000 - mae: 3614.5430 - val_loss: 16123630.0000 - val_mae: 3510.8325\n","Epoch 42/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 16288452.0000 - mae: 3402.4570 - val_loss: 16099857.0000 - val_mae: 3507.4448\n","Epoch 43/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 17582220.0000 - mae: 3608.5830 - val_loss: 16075610.0000 - val_mae: 3503.9866\n","Epoch 44/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 18193182.0000 - mae: 3686.7300 - val_loss: 16051049.0000 - val_mae: 3500.4802\n","Epoch 45/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 17661392.0000 - mae: 3628.0959 - val_loss: 16026309.0000 - val_mae: 3496.9441\n","Epoch 46/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 17936216.0000 - mae: 3639.7188 - val_loss: 16001396.0000 - val_mae: 3493.3806\n","Epoch 47/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 17486052.0000 - mae: 3565.7881 - val_loss: 15976241.0000 - val_mae: 3489.7783\n","Epoch 48/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 18427584.0000 - mae: 3710.8955 - val_loss: 15950676.0000 - val_mae: 3486.1135\n","Epoch 49/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 16905100.0000 - mae: 3523.4441 - val_loss: 15924984.0000 - val_mae: 3482.4268\n","Epoch 50/50\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 18630584.0000 - mae: 3718.3728 - val_loss: 15898682.0000 - val_mae: 3478.6479\n","âœ… LSTM regressor trained and saved.\n"]}]},{"cell_type":"code","source":["# ===== TTI regressor prediction (LSTM-ready) =====\n","import os\n","import numpy as np\n","import joblib\n","from tensorflow import keras\n","\n","# ===== PATHS =====\n","BASE_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project\"  # adjust only if needed\n","PROCESSED_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n","MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n","\n","# ===== LOAD ANOMALIES =====\n","X_anomalies = np.load(os.path.join(PROCESSED_DIR, 'X_anomalies.npy'))\n","print(f\"âœ… X_anomalies loaded: shape = {X_anomalies.shape}\")\n","\n","# ===== LOAD TTI SCALER (joblib) =====\n","tti_scaler = joblib.load(os.path.join(MODELS_DIR, 'tti_scaler.pkl'))\n","print(\"âœ… TTI scaler loaded with joblib.\")\n","\n","# ===== SCALE ANOMALIES PER TIMESTEP =====\n","n_samples, timesteps, n_features = X_anomalies.shape\n","# use float dtype for scaled array\n","X_anomalies_scaled = np.zeros((n_samples, timesteps, n_features), dtype=np.float32)\n","\n","for t in range(timesteps):\n","    # transform each timestep's feature vector (shape: n_samples x n_features)\n","    X_anomalies_scaled[:, t, :] = tti_scaler.transform(X_anomalies[:, t, :])\n","\n","print(\"âœ… Anomalies scaled (per-timestep). Shape:\", X_anomalies_scaled.shape)\n","\n","# ===== LOAD TTI LSTM MODEL =====\n","tti_model = keras.models.load_model(os.path.join(MODELS_DIR, \"tti_lstm_regressor.keras\"))\n","print(\"âœ… TTI model loaded.\")\n","\n","# ===== PREDICT TTI (keep 3D input for LSTM) =====\n","# model expects shape (batch, timesteps, features)\n","tti_predictions = tti_model.predict(X_anomalies_scaled, verbose=0)\n","tti_predictions = np.array(tti_predictions).reshape(-1)  # (n_samples,)\n","print(\"âœ… TTI predictions complete. Example predictions:\", tti_predictions[:10])\n","\n","# ===== SORT ANOMALIES BY SHORTEST TTI =====\n","sorted_indices = np.argsort(tti_predictions)  # ascending: smallest (most urgent) first\n","X_anomalies_prioritized = X_anomalies[sorted_indices]\n","tti_prioritized = tti_predictions[sorted_indices]\n","\n","print(\"\\nğŸ“Š Top prioritized anomalies (shortest TTI first):\")\n","for i, tti in enumerate(tti_prioritized[:10], start=1):\n","    print(f\"{i}. TTI = {tti:.2f} units\")\n","\n","# ===== SAVE PRIORITIZED RESULTS =====\n","np.save(os.path.join(PROCESSED_DIR, 'X_anomalies_prioritized.npy'), X_anomalies_prioritized)\n","np.save(os.path.join(PROCESSED_DIR, 'tti_prioritized.npy'), tti_prioritized)\n","print(\"ğŸ’¾ Saved prioritized anomalies & TTI predictions to processed/\")\n","\n","# ===== Optional: produce a small CSV for quick inspection =====\n","import pandas as pd\n","top_n = min(50, len(tti_prioritized))\n","df_out = pd.DataFrame({\n","    'anomaly_idx': sorted_indices[:top_n],\n","    'predicted_tti': tti_prioritized[:top_n]\n","})\n","df_out.to_csv(os.path.join(PROCESSED_DIR, 'tti_prioritized_top50.csv'), index=False)\n","print(f\"ğŸ’¾ Saved top-{top_n} prioritized list as CSV.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OEhq4IiwX-_","executionInfo":{"status":"ok","timestamp":1754644538334,"user_tz":-330,"elapsed":863,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"c73992a2-7601-4e9f-ba73-fe2c00649d91"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… X_anomalies loaded: shape = (105, 30, 21)\n","âœ… TTI scaler loaded with joblib.\n","âœ… Anomalies scaled (per-timestep). Shape: (105, 30, 21)\n","âœ… TTI model loaded.\n","âœ… TTI predictions complete. Example predictions: [115.39368  115.47932  115.496605 115.45666  115.489044 115.46363\n"," 115.428314 115.45606  115.5001   115.46639 ]\n","\n","ğŸ“Š Top prioritized anomalies (shortest TTI first):\n","1. TTI = 115.20 units\n","2. TTI = 115.28 units\n","3. TTI = 115.32 units\n","4. TTI = 115.36 units\n","5. TTI = 115.38 units\n","6. TTI = 115.38 units\n","7. TTI = 115.38 units\n","8. TTI = 115.38 units\n","9. TTI = 115.38 units\n","10. TTI = 115.39 units\n","ğŸ’¾ Saved prioritized anomalies & TTI predictions to processed/\n","ğŸ’¾ Saved top-50 prioritized list as CSV.\n"]}]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","MODELS_DIR = \"/content/drive/MyDrive/spacecraft_anomaly_project/models\"\n","\n","shutil.copy(\n","    os.path.join(MODELS_DIR, 'scaler.pkl'),\n","    os.path.join(MODELS_DIR, 'tti_scaler.pkl')\n",")\n","print(\"âœ… Copied scaler.pkl to tti_scaler.pkl\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iME5qwqQ2DVx","executionInfo":{"status":"ok","timestamp":1754642641978,"user_tz":-330,"elapsed":168,"user":{"displayName":"Apurva Malasi","userId":"09125563254932778626"}},"outputId":"f314db9b-9d00-4809-c872-99ca5be757b6"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Copied scaler.pkl to tti_scaler.pkl\n"]}]}]}